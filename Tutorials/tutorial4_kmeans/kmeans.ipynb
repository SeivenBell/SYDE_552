{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this notebook is created by kevin zhu for SYDE 522.\n",
    "\n",
    "references used:\n",
    "- https://scikit-learn.org/stable/modules/clustering.html#k-means\n",
    "- https://github.com/aihubprojects/Machine-Learning-From-Scratch/blob/master/K-Means%20from%20Scratch.ipynb\n",
    "- https://muthu.co/mathematics-behind-k-mean-clustering-algorithm/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means clustering\n",
    "\n",
    "(from Wikipedia:)\n",
    ">k-means clustering aims to partition $N$ observations into $K$ clusters in which each observation belongs to the cluster with the nearest mean (cluster centers or cluster centroid)\n",
    "\n",
    "\n",
    "<u> **KMeans algorithm** </u>\n",
    "\n",
    "User specifies number of clusters $K$ to group data into.\n",
    "\n",
    "a) initialize $K$ centroids.\n",
    "\n",
    "b) assign each datapoint to the closest centroid. Compute WCSS based on these labels.\n",
    "\n",
    "c) recompute centroids as the mean of all points belonging to that centroid.\n",
    "\n",
    "Repeat steps (b-c) until WCSS convergences.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries used\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate fake data (with 3 clusters)\n",
    "center_1 = np.array([1,1])\n",
    "center_2 = np.array([5,5])\n",
    "center_3 = np.array([8,1])\n",
    "\n",
    "np.random.seed(711)\n",
    "cluster_1 = np.random.randn(100, 2) + center_1\n",
    "cluster_2 = np.random.randn(100,2) + center_2\n",
    "cluster_3 = np.random.randn(100,2) + center_3\n",
    "data = np.concatenate((cluster_1, cluster_2, cluster_3), axis = 0)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# plot\n",
    "plt.scatter(data[:,0],data[:,1], c='lightskyblue')\n",
    "plt.title('fake data of size {}'.format(data.shape))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. KMeans from scratch (kind of)\n",
    "\n",
    "#### 1a) Initialize K random centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly initialize K=3 centroids\n",
    "K = 3\n",
    "\n",
    "np.random.seed(711)\n",
    "centroids = data[np.random.randint(0, data.shape[0], K)] #randomly pick K points in dataset as centroids\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# plot\n",
    "plt.scatter(data[:,0],data[:,1], c='lightskyblue')\n",
    "plt.scatter(centroids[:,0],centroids[:,1], c = 'red', marker = 'x', s = 100)\n",
    "plt.title('initial random centroids')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1b) Assign observations to closest centroid\n",
    "\n",
    "First, let's compute the distance between each data observation and each centroid. We can use sum of squares $SS$ (or Euclidian distance squared) as our distance metric:\n",
    "\n",
    "For any two $M$-dimension vectors $U = [u_1,..., u_M]$ and $V = [v_1,..., v_M]$:\n",
    "$$\n",
    "SS(U,V) = ||U - V||^2_2 = \\sum_{i=1}^{M} (u_i - v_i)^2\n",
    "$$\n",
    "\n",
    "Let's store all of these distances in a $N$ x $K$ matrix $M_{SS}$ where row $n$ and column $k$ corresponds to the distance between the $n$-th observation and $k$-th centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" \n",
    "Compute sum of squares (SS), or Euclidian distance squared, between each data observation and each centroid.\n",
    "\n",
    "Args:\n",
    "    data (NxM): dataset of M-dimensions with N observations.\n",
    "    centroids (KxM): K centroids of dimension M.\n",
    "\n",
    "Returns:\n",
    "    SS_matrix (NxK): matrix storing squared distances between each observation and each centroid.\n",
    "\"\"\"\n",
    "\n",
    "def compute_distance_matrix(data, centroids):\n",
    "    N = len(data)\n",
    "    K = len(centroids)\n",
    "    \n",
    "    # compute sum of squares between each point and each centroid\n",
    "    # your code here.\n",
    "    SS_matrix = np.random.rand(N,K) #delete this\n",
    "    \n",
    "    return SS_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we assign each observation to the closet centroid.\n",
    "\n",
    "- *i.e.* from our distance matrix $M_{SS}$ we take the index of the column corresponding to the smallest value as the label for the observation)\n",
    "\n",
    "Based on the current labeling (assignment of data observations to centroids), compute the total within-cluster sum of squares $WCSS$:\n",
    "$$\n",
    "\\text{total}\\;\\; WCSS = \\sum_k \\sum_{i\\in C_k} SS(x_i,\\; \\text{centroid}_k) \n",
    "\\quad \\text{or} \\quad \n",
    "\\sum_k \\sum_{\\text{label}(x_i)=k} SS(x_i,\\; \\text{centroid}_k) \n",
    "$$\n",
    "- for each $\\text{centroid}_k$, take the sum of the distances between $\\text{centroid}_k$ and all datapoints $x_i$ that belong to $\\text{centroid}_k$ (closest to $\\text{centroid}_k$). Then sum over all $K$ centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Assign each datapoint to the closest centroid based on a distance matrix. \n",
    "Compute the total WCSS for the corresponding labels. \n",
    "\n",
    "Args:\n",
    "    SS_matrix (NxK): matrix storing squared distances between each observation and each centroid.\n",
    "\n",
    "Returns:\n",
    "    labels (N-sized vector): N labels that assign each data point to a centroid.\n",
    "    WCSS: total WCSS based on current labeling scheme.\n",
    "\"\"\"\n",
    "def assign_centroid(SS_matrix):\n",
    "\n",
    "    N, K = SS_matrix.shape\n",
    "\n",
    "    # assign each point to closest centroid \n",
    "    # your code here.\n",
    "    labels = np.random.randint(0, K, N)  #delete this\n",
    "    \n",
    "    # compute total within cluster sum of squares for the labels\n",
    "    # your code here.\n",
    "    WCSS = np.random.rand() #delete this\n",
    "\n",
    "    return labels, WCSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1b\n",
    "SS_matrix = compute_distance_matrix(data, centroids)\n",
    "labels, WCSS = assign_centroid(SS_matrix)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# plot\n",
    "plt.scatter(data[:,0],data[:,1], c=labels, cmap='Set2')\n",
    "plt.scatter(centroids[:,0],centroids[:,1], c = 'red', marker = 'x', s = 100)\n",
    "plt.title('initial total WCSS = {:.2f}'.format(WCSS))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1c) Update centroids."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the mean of each newly formed cluster (datapoints with the same label), as the updated centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Update centroids as the mean of each cluster.\n",
    "\n",
    "Args:\n",
    "    data (NxM): dataset of M-dimensions with N observations.\n",
    "    labels (N-sized vector): N labels that assign each data point to a centroid.\n",
    "    K (int): number of clusters.\n",
    "\n",
    "Returns:\n",
    "    centroids (KxM): K centroids of dimension M.\n",
    "\"\"\"\n",
    "\n",
    "def update_centroids(data, labels, K):\n",
    "\n",
    "    N,M = data.shape\n",
    "    \n",
    "    # take the mean of each cluster as new centroids\n",
    "    # your code here.\n",
    "    newcentroids = np.random.rand(K,M) #delete this\n",
    "\n",
    "    return newcentroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1c\n",
    "newcentroids = update_centroids(data, labels, K=3)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# plot\n",
    "plt.scatter(data[:,0],data[:,1], c=labels, cmap='Set2')\n",
    "plt.scatter(centroids[:,0],centroids[:,1], c = 'red', marker = 'x', s = 100, label = 'previous')\n",
    "plt.scatter(newcentroids[:,0],newcentroids[:,1], c = 'fuchsia', marker = '^', s = 100, label = 'new')\n",
    "plt.legend()\n",
    "plt.title('initial total WCSS = {:.2f}'.format(WCSS))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat steps 1b and 1c..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat 1b\n",
    "SS_matrix = compute_distance_matrix(data, newcentroids)\n",
    "labels, WCSS = assign_centroid(SS_matrix)\n",
    "# repeat 1c\n",
    "newcentroids2 = update_centroids(data, labels, K=3)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# plot\n",
    "plt.scatter(data[:,0],data[:,1], c=labels, cmap='Set2')\n",
    "plt.scatter(newcentroids[:,0],newcentroids[:,1], c = 'red', marker = 'x', s = 100, label = 'old')\n",
    "plt.scatter(newcentroids2[:,0],newcentroids2[:,1], c = 'fuchsia', marker = '^', s = 100, label = 'new')\n",
    "plt.legend()\n",
    "plt.title('new total WCSS = {:.2f}'.format(WCSS))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat steps 1b-c 9 times..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(9,figsize = (12,12))\n",
    "\n",
    "#initial\n",
    "SS_matrix = compute_distance_matrix(data, centroids)\n",
    "labels, WCSS = assign_centroid(SS_matrix)\n",
    "\n",
    "# iterate J=9 times:\n",
    "J = 9\n",
    "wcss_list = [WCSS] #track wcss over iterations\n",
    "\n",
    "for j in range(J):\n",
    "    newcentroids = update_centroids(data, labels, K=3)\n",
    "    SS_matrix = compute_distance_matrix(data, newcentroids)\n",
    "    labels, WCSS = assign_centroid(SS_matrix)\n",
    "\n",
    "    ax = plt.subplot(331 + j)\n",
    "    plt.scatter(data[:,0],data[:,1], c=labels, cmap='Set2')\n",
    "    plt.scatter(centroids[:,0],centroids[:,1], c = 'red', marker = 'x', s = 100, label = 'prev')\n",
    "    plt.scatter(newcentroids[:,0],newcentroids[:,1], c = 'fuchsia', marker = '^', s = 100, label = 'new')\n",
    "    plt.title('(after {} it.) new WCSS = {:.2f}'.format(j+1, WCSS))\n",
    "    plt.legend()\n",
    "\n",
    "    wcss_list.append(WCSS)\n",
    "    centroids = newcentroids #update previous to new\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how do we determine how many iterations to repeat?\n",
    "\n",
    "\n",
    "#### 1d) Stopping threshrold\n",
    "\n",
    "- when WCSS stops improving,\n",
    "- or when centroids stop moving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot wcss over iterations\n",
    "\n",
    "plt.figure(figsize = (4,3))\n",
    "plt.plot(wcss_list)\n",
    "plt.title('Total WCSS over iterations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting it together..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myKMeans(data, K=3, threshold = 0.01, max_iterations = 500, random_state = 711):\n",
    "        \n",
    "    # step a: initialize centroids\n",
    "    np.random.seed(random_state)\n",
    "    centroids = data[np.random.randint(0, data.shape[0], K)]\n",
    "\n",
    "    prevWCSS = 0\n",
    "    # repeat steps b and c\n",
    "    for j in range(max_iterations):    \n",
    "        \n",
    "        # step b: assign labels\n",
    "        SS_matrix = compute_distance_matrix(data, centroids)\n",
    "        labels, WCSS = assign_centroid(SS_matrix)\n",
    "\n",
    "        # check stopping\n",
    "        improvement = prevWCSS - WCSS\n",
    "        if improvement < threshold and j>0:\n",
    "            #print('myKMeans stopped after {} iterations.'.format(j+1))\n",
    "            return labels, WCSS\n",
    "\n",
    "        # step c: update centroids\n",
    "        centroids = update_centroids(data, labels, K)\n",
    "        prevWCSS = WCSS\n",
    "\n",
    "    return labels, WCSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Comparing to Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "K = 3\n",
    "\n",
    "# sklearn implementaion of kmeans\n",
    "kmeans_sklearn = KMeans(n_clusters=K, random_state = 711)\n",
    "kmeans_sklearn.fit(data) #fit kmeans to data\n",
    "labels_sklearn = kmeans_sklearn.labels_\n",
    "\n",
    "# our implementation:\n",
    "labels_ours, wcss_ours = myKMeans(data, K)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# plot\n",
    "plt.figure(2,figsize = (11,4))\n",
    "ax = plt.subplot(121)\n",
    "plt.scatter(data[:,0],data[:,1], c=labels_sklearn, cmap='Set2')\n",
    "plt.title('KMeans using sklearn')\n",
    "\n",
    "ax = plt.subplot(122)\n",
    "plt.scatter(data[:,0],data[:,1], c=labels_ours, cmap='Set2')\n",
    "plt.title('clustering using myKMeans')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. How to select K?\n",
    "\n",
    "Elbow method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcss_all = []\n",
    "krange = range(1,10) # compute wcss for different K = 1,...,9\n",
    "\n",
    "for k in krange:\n",
    "    labels_k, wcss_k = myKMeans(data, K=k)\n",
    "    wcss_all.append(wcss_k)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# plot\n",
    "plt.figure(figsize = (4,3))\n",
    "plt.plot(krange, wcss_all)\n",
    "plt.title('Elbow method')\n",
    "plt.xlabel('Number of clusters (K)')\n",
    "plt.ylabel('Total WCSS')\n",
    "plt.xticks(np.arange(1,10,2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. When does KMeans fail?\n",
    "\n",
    "\n",
    "#### Poor initial centroids:\n",
    "\n",
    "(source: https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_assumptions.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when does kmeans fail?\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# generate unevenly sized blobs\n",
    "n_samples = 1500\n",
    "random_state = 170\n",
    "X, y = make_blobs(n_samples=n_samples, random_state=random_state)\n",
    "X_filtered = np.vstack(\n",
    "    (X[y == 0][:500], X[y == 1][:100], X[y == 2][:10])\n",
    ")  # Unevenly sized blobs\n",
    "y_filtered = [1] * 500 + [2] * 100 + [0] * 10\n",
    "\n",
    "\n",
    "# our kmeans:\n",
    "K = 3\n",
    "#random state = 100\n",
    "labels, wcss = myKMeans(X_filtered, K, random_state = 100)\n",
    "np.random.seed(100)\n",
    "centroids = X_filtered[np.random.randint(0, X_filtered.shape[0], K)] #initial centroid\n",
    "newcentroids = update_centroids(X_filtered, labels, K) #final centroid\n",
    "\n",
    "#random state = 101\n",
    "labels2, wcss2 = myKMeans(X_filtered, K, random_state = 101)\n",
    "np.random.seed(101)\n",
    "centroids2 = X_filtered[np.random.randint(0, X_filtered.shape[0], K)] #initial centroid\n",
    "newcentroids2 = update_centroids(X_filtered, labels2, K) #final centroid\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# plot\n",
    "plt.figure(3,figsize = (12,4))\n",
    "ax = plt.subplot(131)\n",
    "ax.scatter(X_filtered[:, 0], X_filtered[:, 1], c=y_filtered)\n",
    "ax.set_title(\"True labels\")\n",
    "\n",
    "ax = plt.subplot(132)\n",
    "ax.scatter(X_filtered[:, 0], X_filtered[:, 1], c=labels)\n",
    "plt.scatter(centroids[:,0],centroids[:,1], c = 'red', marker = 'x', s = 100, label = 'initial')\n",
    "plt.scatter(newcentroids[:,0],newcentroids[:,1], c = 'fuchsia', marker = '^', s = 100, label = 'final')\n",
    "plt.legend()\n",
    "ax.set_title(\"myKMeans w/ initial state = 100, \\n total WCSS={:.2f}\".format(wcss))\n",
    "\n",
    "ax = plt.subplot(133)\n",
    "ax.scatter(X_filtered[:, 0], X_filtered[:, 1], c=labels2)\n",
    "plt.scatter(centroids2[:,0],centroids2[:,1], c = 'red', marker = 'x', s = 100, label = 'initial')\n",
    "plt.scatter(newcentroids2[:,0],newcentroids2[:,1], c = 'fuchsia', marker = '^', s = 100, label = 'final')\n",
    "plt.legend()\n",
    "ax.set_title(\"myKMeans w/ initial state = 101, \\n total WCSS={:.2f}\".format(wcss2))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other data distributions:\n",
    "\n",
    "(source: https://scikit-learn.org/stable/modules/clustering.html)\n",
    "\n",
    "![](clustering.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "can we still apply KMeans to all rows above?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
